{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](http://www.lapix.ufsc.br/wp-content/uploads/2019/04/VC2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://drive.google.com/open?id=1r5voXzSv-AFZFyGwgu-UCX7BvrudQDH8\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"https://github.com/awangenh/vision\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/05/GIT-open-in-github-blue-logo.png\" alt=\"Open in Github\" title=\"Open in Github\"></a>&nbsp; &nbsp;<a href=\"https://codigos.ufsc.br/awangenh/vision\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/05/GIT-open-in-gitlab-blue-logo.png\" alt=\"Open in Gitlab\" title=\"Open in Gitlab\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Python-v.3.7-green.png\" alt=\"Python Version\" title=\"Python Version\"></a>\n",
    "\n",
    "<small>Observe that, if you chose to *Open in Colab* you'll be redirected to read-only notebooks that you'll have to right-click on and chose to *Open  in Colab* again.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloning the ***Computer Vision*** repository from a Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clone from our personal Github mirror (may be out of sync):\n",
    "!git clone https://github.com/awangenh/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clone from UFSC's Institutional Gitlab (always the latest version):\n",
    "!git clone https://codigos.ufsc.br/aldo.vw/vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Filters\n",
    "\n",
    "This section discusses simple filters. Some of these filter employ simple mathematical operations, such as mean or media, other employ simples convolutions, such as Gaussian, low-pass, high-pass or band-pass filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters in OpenCV\n",
    "\n",
    "OpenCV implements a huge palette of filters. You'll find some documentation on these pages:\n",
    "- Methods: https://docs.opencv.org/3.4.1/d4/d86/group__imgproc__filter.html\n",
    "- Explanations: https://docs.opencv.org/3.0-beta/modules/imgproc/doc/filtering.html\n",
    "\n",
    "We will demonstrate a few here. OpenCV also allows you to develop any custom convolutional filter using  the OpenCV function [filter2D()](https://docs.opencv.org/3.4.3/d5/df1/group__imgproc__hal__functions.html#ga42c2468ab3a1238fbf48458c57169081) to create your own linear filters. Here's an official tutorial: https://docs.opencv.org/3.4.3/d4/dbd/tutorial_filter_2d.html.\n",
    "\n",
    "Mathematical Morphology filters we will handle in a separate, specific notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Median Blur** smoothes an image using the median filter with the $(\\texttt{ksize} \\times \\texttt{ksize})$ aperture. Each channel of a multi-channel image is processed independently. Parameters:\t\n",
    "\n",
    "    src – input 1-, 3-, or 4-channel image; when ksize is 3 or 5, the image depth should be CV_8U, CV_16U, or CV_32F, for larger aperture sizes, it can only be CV_8U.\n",
    "    dst – destination array of the same size and type as src.\n",
    "    ksize – aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3215a8066d344ce4b49780f7880050fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=11, description='ksize', max=71, min=1, step=2), Button(description='Run…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_median_blur(ksize=11)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# load the image and perform pyramid mean shift filtering\n",
    "# to aid the thresholding step\n",
    "image = cv2.imread(\"../data/car-01.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def my_median_blur(ksize = 11):\n",
    "    global image\n",
    "    # The Median Filter smoothes an image using the median filter.\n",
    "    shifted = cv2.medianBlur(image, ksize=ksize)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols=2, figsize=(20, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original image')\n",
    "\n",
    "    ax[1].imshow(shifted)\n",
    "    ax[1].set_title('Median-Blurred')\n",
    "\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_median_blur, ksize = (1, 71, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Mean Shift Filter** performs the initial step of a meanshift segmentation of an image. Parameters:\t\n",
    "\n",
    "    cv2.pyrMeanShiftFiltering(src, sp, sr[, dst[, maxLevel[, termcrit]]]) → dst\n",
    "    src – The source 8-bit, 3-channel image.\n",
    "    dst – The destination image of the same format and the same size as the source.\n",
    "    sp – The spatial window radius.\n",
    "    sr – The color window radius.\n",
    "    maxLevel – Maximum level of the pyramid for the segmentation.\n",
    "    termcrit – Termination criteria: when to stop meanshift iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d21fd9f557404cbb00af1387c3004b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=21, description='spatialWindow', max=51, min=1, step=2), IntSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_mean_sfift(spatialWindow=21, colorWindow=51)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# load the image and perform pyramid mean shift filtering\n",
    "# to aid the thresholding step\n",
    "image = cv2.imread(\"../data/car-01.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def my_mean_sfift (spatialWindow = 21, colorWindow = 51):\n",
    "    global image\n",
    "    # The Mean Shift Filter performs the initial step of meanshift segmentation of an image.\n",
    "    shifted = cv2.pyrMeanShiftFiltering(image, sp=spatialWindow, sr=colorWindow)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols=2, figsize=(20, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original image')\n",
    "\n",
    "    ax[1].imshow(shifted)\n",
    "    ax[1].set_title('Mean-Shifted')\n",
    "\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_mean_sfift, spatialWindow = (1, 51, 2), colorWindow = (1, 101, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Gaussian filter** blurs an image: The function convolves the source image with the specified Gaussian kernel. Parameters:\t\n",
    "\n",
    "    src – input image; the image can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
    "    dst – output image of the same size and type as src.\n",
    "    ksize – Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd. Or, they can be zero’s and then they are computed from sigma* .\n",
    "    sigmaX – Gaussian kernel standard deviation in X direction.\n",
    "    sigmaY – Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be equal to sigmaX.\n",
    "    borderType – pixel extrapolation method (see borderInterpolate for details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd51d69241b448c2980f73419f3267e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=21, description='ksize', max=51, min=1, step=2), FloatSlider(value=0.5, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_gaussian_blur(ksize=21, sigmaX=0.5)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "import copy\n",
    "\n",
    "# load the image and perform pyramid mean shift filtering\n",
    "# to aid the thresholding step\n",
    "image = cv2.imread(\"../data/car-01.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def my_gaussian_blur (ksize = 21, sigmaX = 0.5):\n",
    "    # The Gaussian filter convolves the source image with the specified Gaussian kernel.\n",
    "    blurred = cv2.GaussianBlur(image, ksize = (ksize, ksize), sigmaX = sigmaX)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols=2, figsize=(20, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original image')\n",
    "\n",
    "    ax[1].imshow(blurred)\n",
    "    ax[1].set_title('Gaussian-Blurred')\n",
    "\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_gaussian_blur, ksize = (1, 51, 2), sigmaX = (0.1, 10.0, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Filters\n",
    "\n",
    "In this section we will discuss more advanced and refined filters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anisotropic Diffusion Filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anisotropic Diffusion Filtering in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National Library of Medicine Insight Segmentation and Registration Toolkit (ITK)\n",
    "\n",
    "ITK (https://itk.org/) has a good implementation of teh Perona&Malik Anisotropic Diffusion Filter: https://itk.org/Doxygen/html/classitk_1_1GradientAnisotropicDiffusionImageFilter.html. ITK is an open-source, cross-platform system that provides developers with an extensive suite of software tools for image analysis.  Developed through extreme programming methodologies, ITK employs leading-edge algorithms for registering and segmenting multidimensional data.\n",
    "\n",
    "Anisotropic diffusion examples can be found here: https://itk.org/ITKExamples/src/Filtering/AnisotropicSmoothing/ComputePeronaMalikAnisotropicDiffusion/Documentation.html\n",
    "\n",
    "ITK is a standard, PyPi-distributed package. If you are running this notebook on the UFSC SeTIC teaching server, ITK will be alredy installed. If you're running this on Colab or elsewhere, ITK Python packages can be installed by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install itk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can import the whole ITK suite by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITK has its own image reading and handling methods, so the code using ITK will look different from your vanilla matplotlib/SciKit/OpenCV code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputImage = \"../data/ct-02.jpg\"\n",
    "outputImage = \"../data/ct-02-diff.jpg\"\n",
    "numberOfIterations = 10\n",
    "conductance = 1.\n",
    "\n",
    "Dimension = 2\n",
    "InputPixelType = itk.UC\n",
    "InputImageType = itk.Image[InputPixelType, Dimension]\n",
    "OutputPixelType = itk.F\n",
    "OutputImageType = itk.Image[OutputPixelType, Dimension]\n",
    "\n",
    "ReaderType = itk.ImageFileReader[InputImageType]\n",
    "reader = ReaderType.New()\n",
    "reader.SetFileName(inputImage)\n",
    "\n",
    "CastFilterType = itk.CastImageFilter[InputImageType, OutputImageType]\n",
    "castfilter = CastFilterType.New()\n",
    "castfilter.SetInput(reader)\n",
    "\n",
    "FilterType = itk.GradientAnisotropicDiffusionImageFilter[OutputImageType, OutputImageType]\n",
    "gradientfilter = FilterType.New()\n",
    "gradientfilter.SetInput(castfilter.GetOutput())\n",
    "gradientfilter.SetNumberOfIterations(numberOfIterations)\n",
    "gradientfilter.SetTimeStep(0.125)\n",
    "gradientfilter.SetConductanceParameter(conductance)\n",
    "\n",
    "WriterType = itk.ImageFileWriter[OutputImageType]\n",
    "writer = WriterType.New()\n",
    "writer.SetFileName(outputImage)\n",
    "writer.SetInput(gradientfilter.GetOutput())\n",
    "\n",
    "writer.Update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Anisotropic Diffusion by Alistair Muldal\n",
    "\n",
    "This is another independent anisotropic filter implementation. Code made available at https://pastebin.com/u/ali_m  Alistair Muldal (ALI_M) is a Research Scientist at Google DeepMind. His Git is https://github.com/alimuldal. In this notebook we will be using my Git mirror, which I adapted for Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this once (or each time you restart the kernel if you're using Colab)\n",
    "# Code below downloads the Python 3 version stored in my mirror\n",
    "# wget parameters: \n",
    "# --backups=1 : renames original file with .1 suffix and writes new file to the intended filename\n",
    "# -q : run quiet unless there's an error\n",
    "!wget  --backups=1 -q https://raw.githubusercontent.com/awangenh/fastaniso/master/fastaniso.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43a33d72e354362a897323c0e7d074b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='niter', max=10000, min=1), IntSlider(value=5, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_fastaniso2D(niter=100, kappa=5, gamma=0.1, step=1.0, option='equation #1')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Import the anisotropic filter \n",
    "from fastaniso import *\n",
    "\n",
    "image = cv2.imread(\"../data/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def my_fastaniso2D(niter=100,kappa=5,gamma=0.1,step=1.,option='equation #1'):\n",
    "    global image\n",
    "    if (option == 'equation #1'):\n",
    "        option = 1\n",
    "    else:\n",
    "        option = 2\n",
    "    output = anisodiff(image, niter=niter,kappa=kappa, gamma=gamma, step=(step,step), option=option, ploton=False)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Original')\n",
    "\n",
    "    # Plot regions using selected colormap...\n",
    "    ax[1].imshow(output, cmap=plt.cm.gray)\n",
    "    ax[1].set_title('Diff 2D')\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_fastaniso2D, niter=(1, 10000), kappa=(1, 100), gamma=(0.01, 1.), step=(1., 10.), option=['equation #1', 'equation #2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
